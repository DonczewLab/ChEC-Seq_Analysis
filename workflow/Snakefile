configfile: "config/config.yml"

###############################################################################
# Steps:
#  1) FastQC
#  2) Adapter Trim (BBDuk)
#  3) Align to S. cerevisiae (primary, no spike-in)
#  4) Align to D. melanogaster (spike-in)
#  5) Create Raw BigWig (from scer)
#  6) Calculate Spike-In Factors (all samples -> single CSV)
#  7) Create Spike-In Normalized BigWigs
#  8) Create CPM Normalized BigWigs
#  9) [Optional] Mean coverage BigWigs
###############################################################################

import os
import pandas as pd

##################################################################
##                    Define input functions                    ##
##################################################################

# Read in sample metadata
samples_df = pd.read_csv(config["samples_csv"])
samples_df.set_index("sample", inplace=True, drop=False)
SAMPLES = samples_df.index.tolist()

def get_fastqs(wildcards):
    """Return dict of R1/R2 FASTQ paths from the samples.csv."""
    row = samples_df.loc[wildcards.sample]
    return {"r1": row["fastq1"], "r2": row["fastq2"]}


##################################################################
##                          Rule All                            ##
##################################################################

rule all:
    """Aggregate all final outputs of the pipeline."""
    input:
        # 1) FastQC
        expand("results/qc/fastqc/{sample}_R1_fastqc.html", sample=SAMPLES),
        expand("results/qc/fastqc/{sample}_R2_fastqc.html", sample=SAMPLES),

        # 2) Trimmed FASTQs
        expand("results/trimmed/{sample}_R1_trimmed.fastq.gz", sample=SAMPLES),
        expand("results/trimmed/{sample}_R2_trimmed.fastq.gz", sample=SAMPLES),

        # 3) scer BAM + BAI
        expand("results/alignment/scer/{sample}.bam", sample=SAMPLES),
        expand("results/alignment/scer/{sample}.bam.bai", sample=SAMPLES),

        # 4) dmel BAM + BAI
        expand("results/alignment/dmel/{sample}.bam", sample=SAMPLES),
        expand("results/alignment/dmel/{sample}.bam.bai", sample=SAMPLES),

        # 5) Raw BigWigs (scer)
        expand("results/bigwig/scer/raw/{sample}_raw.bw", sample=SAMPLES),

        # 6) single CSV with spike-in factors
        "results/spikein_factors/spikein_factors.csv",

        # 7) Spike-in normalized BigWigs (scer)
        expand("results/bigwig/scer/spikein/{sample}_SpikeIn.bw", sample=SAMPLES),

        # 8) CPM BigWigs (scer)
        expand("results/bigwig/scer/cpm/{sample}_CPM.bw", sample=SAMPLES),

        # 9) [Optional] mean coverage BigWigs
        # Uncomment if you actually do replicate merging:
        # expand("results/bigwig/scer/cpm_mean/{sample}_CPM_mean.bw", sample=SAMPLES)
    message:
        "All pipeline outputs have been generated."


###############################################################################
# RULE: FastQC on raw data
###############################################################################
rule fastqc_raw:
    """Run FastQC on raw FASTQs."""
    input:
        get_fastqs
    output:
        html1="results/qc/fastqc/{sample}_R1_fastqc.html",
        zip1 ="results/qc/fastqc/{sample}_R1_fastqc.zip",
        html2="results/qc/fastqc/{sample}_R2_fastqc.html",
        zip2 ="results/qc/fastqc/{sample}_R2_fastqc.zip"
    envmodules:
        config["fastqc"]
    log:
        "results/logs/fastqc/{sample}.log"
    shell:
        """
        fastqc -o results/qc/fastqc {input.r1} {input.r2} 2> {log}

        dir="results/qc/fastqc"
        baseR1=$(basename {input.r1} .fastq.gz)
        mv $dir/${{baseR1}}_fastqc.html {output.html1} || true
        mv $dir/${{baseR1}}_fastqc.zip {output.zip1} || true

        baseR2=$(basename {input.r2} .fastq.gz)
        mv $dir/${{baseR2}}_fastqc.html {output.html2} || true
        mv $dir/${{baseR2}}_fastqc.zip {output.zip2} || true
        """


###############################################################################
# RULE: Adapter Trimming (BBDuk)
###############################################################################
rule trim_adapters:
    """Trim adapters using BBDuk."""
    input:
        get_fastqs
    output:
        r1_trim="results/trimmed/{sample}_R1_trimmed.fastq.gz",
        r2_trim="results/trimmed/{sample}_R2_trimmed.fastq.gz"
    params:
        bbmap_ref=config["bbmap_ref"]
    envmodules:
        config["bbmap"]
    log:
        "results/logs/trim/{sample}.log"
    shell:
        """
        bbduk.sh -Xmx1g \
          in1={input.r1} \
          in2={input.r2} \
          out1={output.r1_trim} \
          out2={output.r2_trim} \
          ref={params.bbmap_ref} \
          k=23 ktrim=r mink=11 hdist=1 tpe=t tbo=t \
          threads=8 2> {log}
        """


###############################################################################
# RULE: Align to S. cerevisiae (primary, no spike-in)
###############################################################################
rule align_scer:
    """Align trimmed reads to S. cerevisiae genome using Bowtie2."""
    input:
        r1="results/trimmed/{sample}_R1_trimmed.fastq.gz",
        r2="results/trimmed/{sample}_R2_trimmed.fastq.gz"
    output:
        bam="results/alignment/scer/{sample}.bam",
        bai="results/alignment/scer/{sample}.bam.bai"
    params:
        bowtie2_idx=config["scer_genome"]
    envmodules:
        config["bowtie2"],
        config["samtools"]
    log:
        "results/logs/alignment/scer/{sample}.log"
    shell:
        """
        bowtie2 --very-sensitive-local --threads 16 \
            -x {params.bowtie2_idx} \
            -1 {input.r1} -2 {input.r2} \
            --maxins 700 --dovetail --no-unal --no-mixed --no-discordant \
            2> {log} | \
        samtools fixmate -O bam -@ 8 -m - - | \
        samtools sort -O bam -@ 8 -o {output.bam}
        samtools index -@ 8 {output.bam} {output.bai}
        """


###############################################################################
# RULE: Align to D. melanogaster (spike-in)
###############################################################################
rule align_dmel:
    """Align trimmed reads to D. melanogaster (spike-in) genome using Bowtie2."""
    input:
        r1="results/trimmed/{sample}_R1_trimmed.fastq.gz",
        r2="results/trimmed/{sample}_R2_trimmed.fastq.gz"
    output:
        bam="results/alignment/dmel/{sample}.bam",
        bai="results/alignment/dmel/{sample}.bam.bai"
    params:
        bowtie2_idx=config["dmel_genome"]
    envmodules:
        config["bowtie2"],
        config["samtools"]
    log:
        "results/logs/alignment/dmel/{sample}.log"
    shell:
        """
        bowtie2 --very-sensitive-local --threads 16 \
            -x {params.bowtie2_idx} \
            -1 {input.r1} -2 {input.r2} \
            --maxins 700 --dovetail --no-unal --no-mixed --no-discordant \
            2> {log} | \
        samtools fixmate -O bam -@ 8 -m - - | \
        samtools sort -O bam -@ 8 -o {output.bam}
        samtools index -@ 8 {output.bam} {output.bai}
        """


###############################################################################
# RULE: Make Raw BigWig (scer)
###############################################################################
rule make_bigwig_raw_scer:
    """Generate raw (no normalization) bigWig from scer BAM."""
    input:
        "results/alignment/scer/{sample}.bam"
    output:
        "results/bigwig/scer/raw/{sample}_raw.bw"
    params:
        binSize=config["binSize"],
        blacklist=config.get("blacklist_scer", "")
    envmodules:
        config["deeptools"]
    log:
        "results/logs/bigwig/scer_raw/{sample}.log"
    shell:
        """
        bamCoverage --bam {input} \
            --outFileName {output} \
            --binSize {params.binSize} \
            --numberOfProcessors 4 \
            --normalizeUsing None \
            {('--blackListFileName ' + params.blacklist) if params.blacklist else ''} \
            2> {log}
        """


###############################################################################
# RULE: Calculate Spike-In Factors (Single CSV for ALL samples)
###############################################################################
rule calc_spikein_factors:
    """
    Gather ALL scer + dmel BAMs, pass them to calc_spikein.py, 
    which writes results/spikein_factors/spikein_factors.csv.
    """
    input:
        scer_bams = expand("results/alignment/scer/{sample}.bam", sample=SAMPLES),
        dmel_bams = expand("results/alignment/dmel/{sample}.bam", sample=SAMPLES)
    output:
        "results/spikein_factors/spikein_factors.csv"
    envmodules:
        config["samtools"],
        config["python"]
    log:
        "results/logs/spikein/calc_spikein.log"
    shell:
        """
        scripts/calc_spikein.py {output} {input.scer_bams} {input.dmel_bams} \
        2> {log}
        """


###############################################################################
# RULE: Make Spike-In Normalized BigWigs (scer)
###############################################################################
rule make_bigwig_scer_spikein:
    """
    Use the factor from spikein_factors.csv to scale coverage in scer BAM, 
    producing spike-in normalized bigWig.
    """
    input:
        bam="results/alignment/scer/{sample}.bam",
        csv="results/spikein_factors/spikein_factors.csv"
    output:
        "results/bigwig/scer/spikein/{sample}_SpikeIn.bw"
    params:
        binSize=config["binSize"],
        blacklist=config.get("blacklist_scer", "")
    envmodules:
        config["deeptools"],
        config["python"]
    log:
        "results/logs/bigwig/spikein/{sample}.log"
shell:
        """
        # Extract factor from the CSV using an inline Python snippet:
        factor=$(python <<EOF
        import csv
        import sys

        sample_name = "{wildcards.sample}"
        factor=1.0
        with open("{input.csv}", "r") as inf:
            reader = csv.DictReader(inf)
            for row in reader:
                if row["sample"] == sample_name:
                    factor = float(row["spikein_factor"])
                    break
        print(factor)
        EOF
        )

        echo "Calculated spike-in factor for {wildcards.sample} = $factor" >> {log}

        # Now run bamCoverage with that factor
        bamCoverage --bam {input.bam} \
                    --outFileName {output} \
                    --binSize {params.binSize} \
                    --numberOfProcessors 4 \
                    --scaleFactor $factor \
                    {('--blackListFileName ' + '{params.blacklist}') if '{params.blacklist}' else ''} \
                    2>> {log}
        """

###############################################################################
# RULE: Make CPM BigWigs (scer)
###############################################################################
rule make_bigwig_scer_cpm:
    """
    Generate CPM-normalized bigWig from scer BAM.
    """
    input:
        "results/alignment/scer/{sample}.bam"
    output:
        "results/bigwig/scer/cpm/{sample}_CPM.bw"
    params:
        binSize=config["binSize"],
        blacklist=config.get("blacklist_scer", "")
    envmodules:
        config["deeptools"]
    log:
        "results/logs/bigwig/scer_cpm/{sample}.log"
    shell:
        """
        bamCoverage --bam {input} \
            --outFileName {output} \
            --binSize {params.binSize} \
            --numberOfProcessors 4 \
            --normalizeUsing CPM \
            {('--blackListFileName ' + params.blacklist) if params.blacklist else ''} \
            2> {log}
        """


# ==============================================================================
# OPTIONAL: Mean Coverage BigWigs (if you have replicates you want to merge)
# ==============================================================================
rule make_bedgraph_scer_cpm:
    """
    Make bedGraph with CPM normalization for scer BAM.
    """
    input:
        "results/alignment/scer/{sample}.bam"
    output:
        "results/bedgraph/scer/cpm/{sample}.bg"
    params:
        binSize=config["binSize"],
        blacklist=config.get("blacklist_scer", "")
    envmodules:
        config["deeptools"]
    log:
        "results/logs/bedgraph/scer_cpm/{sample}.log"
    shell:
        """
        bamCoverage --bam {input} \
            --outFileName {output} \
            --outFileFormat bedgraph \
            --binSize {params.binSize} \
            --numberOfProcessors 4 \
            --normalizeUsing CPM \
            {('--blackListFileName ' + params.blacklist) if params.blacklist else ''} \
            2> {log}
        """

rule merge_bedgraphs_mean_cpm:
    """
    Union multiple replicate bedGraphs for a sample, compute mean coverage.
    Adjust 'rep' in expand(...) if you have N replicates or different naming.
    """
    input:
        expand("results/bedgraph/scer/cpm/{{sample}}_{rep}.bg", rep=["1","2","3"])
    output:
        "results/bedgraph/scer/cpm_mean/{sample}.bg"
    envmodules:
        config["bedtools"]
    log:
        "results/logs/bedgraph/merge_{sample}.log"
    shell:
        r"""
        bedtools unionbedg -i {input} | \
        awk 'OFS="\t" {
          sum=0; for (i=4; i<=NF; i++) sum+=$i;
          print $1,$2,$3,sum/(NF-3)
        }' | sort -k1,1 -k2,2n > {output}
        """

rule bedgraph_to_bigwig_mean_cpm:
    """
    Convert the mean-coverage bedGraph to BigWig.
    """
    input:
        "results/bedgraph/scer/cpm_mean/{sample}.bg"
    output:
        "results/bigwig/scer/cpm_mean/{sample}_CPM_mean.bw"
    params:
        genome_file=config["genome_file_scer"]
    envmodules:
        config["ucsc"]
    log:
        "results/logs/bedgraph/bw_mean_{sample}.log"
    shell:
        """
        bedGraphToBigWig {input} {params.genome_file} {output} 2> {log}
        """
